{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import necessary libraries\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import sklearn\n",
    "import keras\n",
    "from keras.layers import Dense\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM\n",
    "import numpy as np\n",
    "import torch\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import SimpleRNN\n",
    "from tensorflow.keras.layers import RNN\n",
    "from tensorflow.keras.layers import Flatten\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.layers import Embedding\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from sklearn.model_selection import KFold\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import scipy as sp\n",
    "import imblearn\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from imblearn.under_sampling import RandomUnderSampler"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Balancing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "d1 = pd.read_csv(\"../data/extracted/d1.csv\")\n",
    "d2 = pd.read_csv(\"../data/extracted/d2.csv\")\n",
    "test = pd.read_csv(\"../data/extracted/test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "d1_X = d1['txt'].values\n",
    "d1_Y = d1['label'].values\n",
    "d2_X = d2['txt'].values\n",
    "d2_Y = d2['label'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define oversampling strategy\n",
    "oversample = RandomOverSampler(sampling_strategy = 0.5)\n",
    "# define undersampling strategy\n",
    "undersample = RandomUnderSampler(sampling_strategy=0.035)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "d1_X_r = d1_X.reshape(-1, 1)\n",
    "d2_X_r = d2_X.reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "d1_X_under, d1_Y_under = undersample.fit_resample(d1_X_r, d1_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "d2_X_over, d2_Y_over = oversample.fit_resample(d2_X_r, d2_Y)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Domain 1 dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Splitting dataset into training and testing dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,Y_train,Y_test = train_test_split(d1_X_under,d1_Y_under,test_size=0.2,random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_r = X_train.reshape(-1,)\n",
    "X_test_r = X_test.reshape(-1,)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = Tokenizer()\n",
    "t.fit_on_texts(X_train_r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "E_train = t.texts_to_sequences(X_train_r)\n",
    "E_test = t.texts_to_sequences(X_test_r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_len = []\n",
    "sum_len = 0\n",
    "max_lenth = 0\n",
    "min_lenght = 10\n",
    "for i in range(len(E_train)):\n",
    "    max_len.append(len(E_train[i]))\n",
    "    sum_len += len(E_train[i])\n",
    "    if len(E_train[i]) > max_lenth:\n",
    "        max_lenth = len(E_train[i])\n",
    "    elif len(E_train[i]) < min_lenght:\n",
    "        min_lenght = len(E_train[i])\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_length = 150\n",
    "padded_train = pad_sequences(E_train, maxlen=max_length, padding='post')\n",
    "padded_test = pad_sequences(E_test, maxlen=max_length, padding='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = len(t.word_index) + 1\n",
    "\n",
    "# define the model\n",
    "RNN = Sequential()\n",
    "RNN.add(Embedding(words, 50, input_length=max_length))\n",
    "RNN.add(SimpleRNN(50, return_sequences=False))\n",
    "# model.add(tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(24)))\n",
    "RNN.add(Dense(1, activation='sigmoid'))\n",
    "RNN.compile(optimizer='adam', loss='binary_crossentropy', metrics=['TrueNegatives'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "2588/2588 [==============================] - 54s 20ms/step - loss: 0.1025 - true_negatives: 958.0000 - val_loss: 0.1034 - val_true_negatives: 324.0000\n",
      "Epoch 2/50\n",
      "2588/2588 [==============================] - 53s 20ms/step - loss: 0.0974 - true_negatives: 954.0000 - val_loss: 0.1114 - val_true_negatives: 354.0000\n",
      "Epoch 3/50\n",
      "2588/2588 [==============================] - 52s 20ms/step - loss: 0.0872 - true_negatives: 1052.0000 - val_loss: 0.1022 - val_true_negatives: 277.0000\n",
      "Epoch 4/50\n",
      "2588/2588 [==============================] - 53s 21ms/step - loss: 0.0894 - true_negatives: 1000.0000 - val_loss: 0.1058 - val_true_negatives: 204.0000\n",
      "Epoch 5/50\n",
      "2588/2588 [==============================] - 54s 21ms/step - loss: 0.0882 - true_negatives: 1014.0000 - val_loss: 0.1071 - val_true_negatives: 330.0000\n",
      "Epoch 6/50\n",
      "2588/2588 [==============================] - 54s 21ms/step - loss: 0.0870 - true_negatives: 1048.0000 - val_loss: 0.1014 - val_true_negatives: 301.0000\n",
      "Epoch 7/50\n",
      "2588/2588 [==============================] - 55s 21ms/step - loss: 0.0773 - true_negatives: 1115.0000 - val_loss: 0.1052 - val_true_negatives: 265.0000\n",
      "Epoch 8/50\n",
      "2588/2588 [==============================] - 55s 21ms/step - loss: 0.0776 - true_negatives: 1083.0000 - val_loss: 0.1090 - val_true_negatives: 347.0000\n",
      "Epoch 9/50\n",
      "2588/2588 [==============================] - 55s 21ms/step - loss: 0.0735 - true_negatives: 1216.0000 - val_loss: 0.1157 - val_true_negatives: 320.0000\n",
      "Epoch 10/50\n",
      "2588/2588 [==============================] - 56s 21ms/step - loss: 0.0700 - true_negatives: 1438.0000 - val_loss: 0.1202 - val_true_negatives: 341.0000\n",
      "Epoch 11/50\n",
      "2588/2588 [==============================] - 56s 22ms/step - loss: 0.0697 - true_negatives: 1324.0000 - val_loss: 0.1239 - val_true_negatives: 343.0000\n",
      "Epoch 12/50\n",
      "2588/2588 [==============================] - 56s 22ms/step - loss: 0.0657 - true_negatives: 1331.0000 - val_loss: 0.1338 - val_true_negatives: 42.0000\n",
      "Epoch 13/50\n",
      "2588/2588 [==============================] - 56s 22ms/step - loss: 0.0568 - true_negatives: 1724.0000 - val_loss: 0.1377 - val_true_negatives: 219.0000\n",
      "Epoch 14/50\n",
      "2588/2588 [==============================] - 56s 22ms/step - loss: 0.0508 - true_negatives: 1803.0000 - val_loss: 0.1372 - val_true_negatives: 306.0000\n",
      "Epoch 15/50\n",
      "2588/2588 [==============================] - 56s 22ms/step - loss: 0.0633 - true_negatives: 1215.0000 - val_loss: 0.1437 - val_true_negatives: 373.0000\n",
      "Epoch 16/50\n",
      "2588/2588 [==============================] - 56s 22ms/step - loss: 0.0573 - true_negatives: 1543.0000 - val_loss: 0.1485 - val_true_negatives: 360.0000\n",
      "Epoch 16: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fd3f275a0b0>"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "early_stop = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=10)\n",
    "RNN.fit(x=padded_train,y=Y_train,epochs=50,validation_data=(padded_test, Y_test), verbose=1,callbacks=[early_stop])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "\n",
    "def c_report(y_true, y_pred):\n",
    "   print(\"Classification Report\")\n",
    "   print(classification_report(y_true, y_pred))\n",
    "   acc_sc = accuracy_score(y_true, y_pred)\n",
    "   print(\"Accuracy : \"+ str(acc_sc))\n",
    "   return acc_sc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.41      0.50      0.45       717\n",
      "           1       0.98      0.97      0.98     19983\n",
      "\n",
      "    accuracy                           0.96     20700\n",
      "   macro avg       0.70      0.74      0.72     20700\n",
      "weighted avg       0.96      0.96      0.96     20700\n",
      "\n",
      "Accuracy : 0.9578743961352657\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9578743961352657"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c_report(Y_test, preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "647/647 [==============================] - 3s 5ms/step\n"
     ]
    }
   ],
   "source": [
    "preds = (model.predict(padded_test) > 0.5).astype(\"int32\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = test.iloc[:600,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "txt = test['txt'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "E_train_ = t.texts_to_sequences(X_train_r)\n",
    "E_test = t.texts_to_sequences(txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "padded_test = pad_sequences(E_test, maxlen=max_length, padding='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19/19 [==============================] - 0s 5ms/step\n"
     ]
    }
   ],
   "source": [
    "pred = RNN.predict(padded_test)>0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pd.DataFrame(pred, columns=['Predictions'])\n",
    "results['Predicted'] = 0\n",
    "results.loc[results['Predictions']==1, 'Predicted'] = 1\n",
    "final_results = results['Predicted']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_results.to_csv(\"../data/RNN_600_undersampled.csv\", index=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
